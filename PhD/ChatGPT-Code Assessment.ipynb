{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885943e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAIError\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# Function to read code files from the folder\n",
    "def read_code_files(folder_path):\n",
    "    code_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") or filename.endswith(\".java\") or filename.endswith(\".cpp\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                code = file.read()\n",
    "                code_files.append((filename, code))\n",
    "    return code_files\n",
    "\n",
    "# Function to create the assessment prompt\n",
    "def create_assessment_prompt(student_code, ref_codes):\n",
    "    refcode_details = \"\\n\\n\".join([f\"Reference Code ({i+1}):\\n{code}\" for i, code in enumerate(ref_codes)])\n",
    "    prompt = (\n",
    "        \"You are an AI designed to assess the entry-level programming exams at an academic level. \"\n",
    "        \"Your expertise lies in segmenting the answer codes based on the most similar reference code, assessing each segment of code under the \\\"ASSESSMENT\\\" comments \"\n",
    "        \"and grading it based on the grade in the most similar reference code. \"\n",
    "        \"Grade of each segment can no be higher than the segment grade of the ref code. \"\n",
    "        \"You can use both dynamic and static code assessment. \"\n",
    "        \"You can also use abstract syntax trees, control flow graphs, and data flow graphs of each segment to make assessments properly. \"\n",
    "        \"Your main goal is to assess the code like an instructor and grade it partially even if it is not correct totally. \"\n",
    "        \"Follow the steps below.\\n\\n\"\n",
    "        \"Step 1 - Every \\\"ASSESSMENT\\\" comment represents a segment in the reference code. Compare the answer code to the reference code and define its segments according to the reference code.\\n\"\n",
    "        \"Step 2 - Assess each segment and grade all of them by using dynamic and static code assessment methods.\\n\"\n",
    "        \"Step 3 - Support your assessment by comparing segments using their graph models; abstract syntax trees, control flow graphs, and data flow graphs.\\n\"\n",
    "        \"Step 4 - Calculate the score and grade each segment according to your assessment.\\n\"\n",
    "        \"Step 5 - Grades should be integer and not bigger than the reference code's segment grade.\\n\\n\"\n",
    "        \"Step 6 - Just provide segment grades in numbers only in a line as the response without titles and any extra details.\\n\\n\"\n",
    "        f\"Reference Codes:\\n{refcode_details}\\n\\n\"\n",
    "        f\"Student Code:\\n{student_code}\\n\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Function to assess code using OpenAI API\n",
    "def assess_code(student_code, ref_codes):\n",
    "    prompt = create_assessment_prompt(student_code, ref_codes)\n",
    "    \n",
    "    openai.api_key = 'XXXX'\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4\",\n",
    "            max_tokens=1500, \n",
    "            temperature=0.1,\n",
    "            top_p=0.1\n",
    "        )\n",
    "        result_text = response.choices[0].message.content\n",
    "        #print(result_text)\n",
    "        return result_text\n",
    "    except OpenAIError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error occurred during assessment.\"\n",
    "\n",
    "# Assess all code files and store the results\n",
    "def assess_all_code_files(folder_path):\n",
    "    code_files = read_code_files(folder_path)\n",
    "    ref_codes = [(filename, code) for filename, code in code_files if filename.lower().startswith(\"refcode\")]\n",
    "    student_codes = [(filename, code) for filename, code in code_files if not filename.lower().startswith(\"refcode\")]\n",
    "    results = []\n",
    "    for filename, code in student_codes:\n",
    "        assessment = assess_code(code, [ref_code for _, ref_code in ref_codes])  \n",
    "        #parts = assessment.split(\"\\n\\n\")\n",
    "        #grade = parts[0].strip() if len(parts) > 0 else \"\"\n",
    "        #segmentscores = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        print((filename[:-4]) + \" \" + assessment)\n",
    "        results.append((filename[:-4]) + \" \" + assessment)\n",
    "    return results\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(current_dir)\n",
    "folder_name = input(\"Please enter the folder name: \")\n",
    "print(folder_name)\n",
    "folder_path = os.path.join(current_dir, folder_name)\n",
    "\n",
    "# Assess all code files in the folder\n",
    "results = assess_all_code_files(folder_path)\n",
    "print(results)\n",
    "\n",
    "processed_data = [line.replace('\\n', ' ').split() for line in results]\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# CSV file name with timestamp\n",
    "filename = f\"{folder_name}/assessment_{timestamp}.csv\"\n",
    "\n",
    "# Writing to the CSV file\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(processed_data)\n",
    "\n",
    "print(\"Data has been written to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c2630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
