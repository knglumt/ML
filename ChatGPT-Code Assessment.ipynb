{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885943e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umitk\\OneDrive\\Documents\\Python Scripts\n",
      "Please enter the folder name: data\\Midterm1-Annotated\\Q1\n",
      "data\\Midterm1-Annotated\\Q1\n",
      "S017511 0 2 0 0 1 0\n",
      "S017665 1 0 0 0 0 1\n",
      "S018062 1 2 0 0 0 1\n",
      "S018152 1 0 0 0 0 0\n",
      "S018298 1 4 0 0 0 1\n",
      "S018706 1 2 1 2 2 1\n",
      "S018718 0 0 0 0 0 0 0 0\n",
      "S020606 1 4 1 8 1\n",
      "S020691 1 4 1 2 3 1\n",
      "S020953 1 4 1 4 2 1\n",
      "S021226 1 4 0 0 0 1\n",
      "S021343 1 2 0 0 0 1\n",
      "S021397 1 3 1 3 1 1\n",
      "S021433 1 0 0 0 0 1\n",
      "S021534 1 0 0 0 0 1\n",
      "S021731 1 3 1 0 0 1\n",
      "S021744 1 0 0 0 0 1\n",
      "S021760 1 0 0 0 1 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\httpx\\_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22280\\3512443207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;31m# Assess all code files in the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massess_all_code_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22280\\3512443207.py\u001b[0m in \u001b[0;36massess_all_code_files\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstudent_codes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0massessment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massess_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mref_code\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mref_codes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;31m#parts = assessment.split(\"\\n\\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m#grade = parts[0].strip() if len(parts) > 0 else \"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22280\\3512443207.py\u001b[0m in \u001b[0;36massess_code\u001b[1;34m(student_code, ref_codes)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         response = openai.chat.completions.create(\n\u001b[0m\u001b[0;32m     50\u001b[0m             messages=[\n\u001b[0;32m     51\u001b[0m                 {\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_utils\\_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\resources\\chat\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 606\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m    607\u001b[0m             \u001b[1;34m\"/chat/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m             body=maybe_transform(\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m         )\n\u001b[1;32m-> 1240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m     def patch(\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[1;32m--> 921\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m                 return self._retry_request(\n\u001b[0m\u001b[0;32m   1006\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\prgs\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# different thread if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         return self._request(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAIError\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# Function to read code files from the folder\n",
    "def read_code_files(folder_path):\n",
    "    code_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\") or filename.endswith(\".java\") or filename.endswith(\".cpp\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                code = file.read()\n",
    "                code_files.append((filename, code))\n",
    "    return code_files\n",
    "\n",
    "# Function to create the assessment prompt\n",
    "def create_assessment_prompt(student_code, ref_codes):\n",
    "    refcode_details = \"\\n\\n\".join([f\"Reference Code ({i+1}):\\n{code}\" for i, code in enumerate(ref_codes)])\n",
    "    prompt = (\n",
    "        \"You are an AI designed to assess the entry-level programming exams at an academic level. \"\n",
    "        \"Your expertise lies in segmenting the answer codes based on the most similar reference code, assessing each segment of code under the \\\"ASSESSMENT\\\" comments \"\n",
    "        \"and grading it based on the grade in the most similar reference code. \"\n",
    "        \"Grade of each segment can no be higher than the segment grade of the ref code. \"\n",
    "        \"You can use both dynamic and static code assessment. \"\n",
    "        \"You can also use abstract syntax trees, control flow graphs, and data flow graphs of each segment to make assessments properly. \"\n",
    "        \"Your main goal is to assess the code like an instructor and grade it partially even if it is not correct totally. \"\n",
    "        \"Follow the steps below.\\n\\n\"\n",
    "        \"Step 1 - Every \\\"ASSESSMENT\\\" comment represents a segment in the reference code. Compare the answer code to the reference code and define its segments according to the reference code.\\n\"\n",
    "        \"Step 2 - Assess each segment and grade all of them by using dynamic and static code assessment methods.\\n\"\n",
    "        \"Step 3 - Support your assessment by comparing segments using their graph models; abstract syntax trees, control flow graphs, and data flow graphs.\\n\"\n",
    "        \"Step 4 - Calculate the score and grade each segment according to your assessment.\\n\"\n",
    "        \"Step 5 - Grades should be integer and not bigger than the reference code's segment grade.\\n\\n\"\n",
    "        \"Step 6 - Just provide segment grades in numbers only in a line as the response without titles and any extra details.\\n\\n\"\n",
    "        f\"Reference Codes:\\n{refcode_details}\\n\\n\"\n",
    "        f\"Student Code:\\n{student_code}\\n\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Function to assess code using OpenAI API\n",
    "def assess_code(student_code, ref_codes):\n",
    "    prompt = create_assessment_prompt(student_code, ref_codes)\n",
    "    \n",
    "    openai.api_key = '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'\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4\",\n",
    "            max_tokens=1500, \n",
    "            temperature=0.1,\n",
    "            top_p=0.1\n",
    "        )\n",
    "        result_text = response.choices[0].message.content\n",
    "        #print(result_text)\n",
    "        return result_text\n",
    "    except OpenAIError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error occurred during assessment.\"\n",
    "\n",
    "# Assess all code files and store the results\n",
    "def assess_all_code_files(folder_path):\n",
    "    code_files = read_code_files(folder_path)\n",
    "    ref_codes = [(filename, code) for filename, code in code_files if filename.lower().startswith(\"refcode\")]\n",
    "    student_codes = [(filename, code) for filename, code in code_files if not filename.lower().startswith(\"refcode\")]\n",
    "    results = []\n",
    "    for filename, code in student_codes:\n",
    "        assessment = assess_code(code, [ref_code for _, ref_code in ref_codes])  \n",
    "        #parts = assessment.split(\"\\n\\n\")\n",
    "        #grade = parts[0].strip() if len(parts) > 0 else \"\"\n",
    "        #segmentscores = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "        print((filename[:-4]) + \" \" + assessment)\n",
    "        results.append((filename[:-4]) + \" \" + assessment)\n",
    "    return results\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(current_dir)\n",
    "folder_name = input(\"Please enter the folder name: \")\n",
    "print(folder_name)\n",
    "folder_path = os.path.join(current_dir, folder_name)\n",
    "\n",
    "# Assess all code files in the folder\n",
    "results = assess_all_code_files(folder_path)\n",
    "print(results)\n",
    "\n",
    "processed_data = [line.replace('\\n', ' ').split() for line in results]\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# CSV file name with timestamp\n",
    "filename = f\"{folder_name}/assessment_{timestamp}.csv\"\n",
    "\n",
    "# Writing to the CSV file\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(processed_data)\n",
    "\n",
    "print(\"Data has been written to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c2630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
